{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Loading Modules**\n",
        "\n"
      ],
      "metadata": {
        "id": "by7-yHTC5mlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnKDnr5lZThX",
        "outputId": "447943d5-99d0-4ea4-9368-f1270cccc0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3xDxYmW9geV"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import image\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from skimage import color\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.layers import InputLayer, Input, Concatenate\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout,GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import  Model\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras\n",
        "import visualkeras"
      ],
      "metadata": {
        "id": "SKptLkZ89cws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing opencv version 4.6.0**"
      ],
      "metadata": {
        "id": "ufedshrn6G78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCjKfux1eYxx"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall opencv-python==4.1.2 \n",
        "#  !pip install opencv-python==4.6.0.66\n",
        "cv2.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset prepation**"
      ],
      "metadata": {
        "id": "dP0AuFnr6T_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHr8CgfJ9sKe",
        "outputId": "055b98e9-de14-465f-d917-071fbfdab3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>Reading  UpdatedSpam\n",
            "1\n",
            ">>>Reading  HAM\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ],
      "source": [
        "#removing duplicate images from dataset using hashing\n",
        "DATA_PATH = '/content/drive/MyDrive/Updated Dataset/'\n",
        "spamData=[]\n",
        "label=[]\n",
        "hashList=[]\n",
        "count=2\n",
        "#from PIL import Image\n",
        "#image.LOAD_TRUNCATED_IMAGES = True\n",
        "for folder in os.listdir(DATA_PATH):\n",
        "    if folder==\"UpdatedHam\":\n",
        "      continue;\n",
        "    print(\">>>Reading \",folder)\n",
        "    count-=1\n",
        "    print(count)\n",
        "    \n",
        "    for file in os.listdir(DATA_PATH+folder):\n",
        "         if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n",
        "            img = image.imread(DATA_PATH+folder+'/'+file)#open ki jagah imread\n",
        "            hsh = hash(tuple(np.array(img).flatten()))\n",
        "            if(hsh not in hashList):\n",
        "              spamData.append(resize(img, (156, 156, 3)))\n",
        "              hashList.append(hsh)\n",
        "              label.append(count)\n",
        "spamDataarr=np.array(spamData)\n",
        "labelarr=np.array(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7dRZ9j3N_3le"
      },
      "outputs": [],
      "source": [
        "#specifying result path\n",
        "resultPath = '/content/drive/MyDrive/Result'\n",
        "train_folder = os.listdir(DATA_PATH).remove(\"UpdatedHam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4jv94eHk_71c"
      },
      "outputs": [],
      "source": [
        "# visulaizing dataset\n",
        "print(\"Spam data shape : \",spamDataarr.shape,\" Label shape : \",labelarr.shape)\n",
        "print(\"Number of SPAM\",len(labelarr[labelarr==0]))\n",
        "print(\"Number of HAM\",len(labelarr[labelarr==1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9l2MRbFmAFuN"
      },
      "outputs": [],
      "source": [
        "# splitting dataset into test and train\n",
        "#test_valid_Percentage = 0.3\n",
        "testPercentage=0.3\n",
        "x_train,x_test,y_train,y_test = train_test_split(spamDataarr,labelarr,test_size = testPercentage,random_state=50, stratify=label,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nzKZaGgAAIRM"
      },
      "outputs": [],
      "source": [
        "#checking shape of dataset\n",
        "print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n",
        "print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)\n",
        "print(\"Number of train SPAM\",len(y_train[y_train==0]))\n",
        "print(\"Number of train HAM\",len(y_train[y_train==1]))\n",
        "\n",
        "print(\"Number of test SPAM\",len(y_test[y_test==0]))\n",
        "print(\"Number of test HAM\",len(y_test[y_test==1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Shift and HOG feature extraction**"
      ],
      "metadata": {
        "id": "9vbMEeld8r9s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NsXtbvNAAN27"
      },
      "outputs": [],
      "source": [
        "# extracting grayscale dataset from rgb dataset\n",
        "data_gray_train = [ color.rgb2gray(i) for i in x_train]\n",
        "data_gray_test = [ color.rgb2gray(i) for i in x_test]\n",
        "data_gray_train=np.array(data_gray_train)\n",
        "data_gray_test=np.array(data_gray_test)\n",
        "print(data_gray_train.shape)\n",
        "print(data_gray_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tt1yHbJym1hR"
      },
      "outputs": [],
      "source": [
        "# extracting shift features (train)\n",
        "sift_features_train=[]\n",
        "for image1 in data_gray_train:\n",
        "  feature_extractor = cv2.SIFT_create()\n",
        "  image2 = cv2.normalize(image1, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
        "  kp_l, desc_l = feature_extractor.detectAndCompute(image2, None)\n",
        "  sift_features_train.append(desc_l)\n",
        "sift_features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CWocQQxTnDvp"
      },
      "outputs": [],
      "source": [
        "# extracting shift features (test)\n",
        "sift_features_test=[]\n",
        "for image1 in data_gray_test:\n",
        "  feature_extractor = cv2.SIFT_create()\n",
        "  image2 = cv2.normalize(image1, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
        "  kp_l, desc_l = feature_extractor.detectAndCompute(image2, None)\n",
        "  sift_features_test.append(resize(desc_l, (50, 128, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PRvTX0opsXTR"
      },
      "outputs": [],
      "source": [
        "# resing shift features using bag of words model\n",
        "center_train=[]\n",
        "kmeans = KMeans(n_clusters=100, random_state=0)\n",
        "for i in sift_features_train:\n",
        " (x,y)=i.shape\n",
        " if x<100:\n",
        "   i=resize(i,(100,128))\n",
        "   clusters = kmeans.fit_predict(i)\n",
        "   center_train.append(kmeans.cluster_centers_)\n",
        " else:\n",
        "   clusters = kmeans.fit_predict(i)\n",
        " #print(kmeans.cluster_centers_.shape)\n",
        "   center_train.append(kmeans.cluster_centers_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jRt-jUJStrqy"
      },
      "outputs": [],
      "source": [
        "# converting to numpy array\n",
        "sift_features_train=np.array(sift_features_train)\n",
        "sift_features_test=np.array(sift_features_test)\n",
        "print(sift_features_train.shape)\n",
        "print(sift_features_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GMS-f4KHAQie"
      },
      "outputs": [],
      "source": [
        "#HOG feature extraction (train)\n",
        "hog_image_train = []\n",
        "for image in data_gray_train:\n",
        "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                \tcells_per_block=(2, 2), visualize=True)\n",
        "    hog_image_train.append(hog_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2zPzgsjMASl0"
      },
      "outputs": [],
      "source": [
        "#HOG feature extraction (test)\n",
        "hog_image_test = []\n",
        "for image in data_gray_test:\n",
        "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                \tcells_per_block=(2, 2), visualize=True)\n",
        "    hog_image_test.append(hog_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UV0zz3tnATy1"
      },
      "outputs": [],
      "source": [
        "# converting to numpy array\n",
        "hog_image_train=np.array(hog_image_train)\n",
        "hog_image_test=np.array(hog_image_test)\n",
        "print(hog_image_train.shape)\n",
        "print(hog_image_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "MClkx6bO9EKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Aixh3lq1VLku"
      },
      "outputs": [],
      "source": [
        "# importing pretrained VGG19 model\n",
        "vgg = VGG19(weights='imagenet', include_top=False, input_shape=(156, 156, 3))\n",
        "vgg.trainable= False\n",
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3lAp5lBoVc_Z"
      },
      "outputs": [],
      "source": [
        "# Top stream model\n",
        "inp1= Input((156,156,3))\n",
        "x1=vgg(inp1)\n",
        "x1=Flatten()(x1)\n",
        "x1 = Dense(512,activation='relu')(x1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = Dense(128,activation='relu')(x1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = BatchNormalization()(x1)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "m1 = Model(inp1, out1)\n",
        "\n",
        "m1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2LOIVd1RpDf5"
      },
      "outputs": [],
      "source": [
        "# visualizing model\n",
        "visualkeras.layered_view(model_final, legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K56W-8_NYEeg"
      },
      "outputs": [],
      "source": [
        "# Middle stream model\n",
        "inp2 = Input((156,156,1))\n",
        "x2=Conv2D(32,kernel_size=3, padding='same',activation='relu')(inp2)\n",
        "x2=MaxPool2D(pool_size=(3, 3))(x2)\n",
        "x2=Conv2D(64,kernel_size=3, padding='same',activation='relu')(x2)\n",
        "x2=MaxPool2D(pool_size=(3, 3))(x2)\n",
        "x2=Conv2D(128,kernel_size=3, padding='same',activation='relu')(x2)\n",
        "x2=Dropout(0.1)(x2)\n",
        "x2=Flatten()(x2)\n",
        "x2 = Dense(512,activation='relu')(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "x2 = Dense(128,activation='relu')(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "x2 = BatchNormalization()(x2)\n",
        "out2 = Dense(1, activation='sigmoid')(x2)\n",
        "m2 = Model(inp2, out2)\n",
        "m2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s4fe-xP4uxHX"
      },
      "outputs": [],
      "source": [
        "# Bottom stream model\n",
        "inp3= Input((50,128,1))\n",
        "x3=Conv2D(32,kernel_size=3, padding='same',activation='relu')(inp3)\n",
        "x3=MaxPool2D(pool_size=(2, 2))(x3)\n",
        "x3=Conv2D(64,kernel_size=3, padding='same',activation='relu')(x3)\n",
        "x3=MaxPool2D(pool_size=(2, 2))(x3)\n",
        "x3=Conv2D(128,kernel_size=3, padding='same',activation='relu')(x3)\n",
        "x3=Dropout(0.1)(x3)\n",
        "x3=Flatten()(x3)\n",
        "x3 = Dense(512,activation='relu')(x3)\n",
        "x3 = Dropout(0.3)(x3)\n",
        "x3 = Dense(128,activation='relu')(x3)\n",
        "x3 = BatchNormalization()(x3)\n",
        "out3 = Dense(1, activation='sigmoid')(x3)\n",
        "m3 = Model(inp3, out3)\n",
        "\n",
        "m3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2SEhEh2en2zN"
      },
      "outputs": [],
      "source": [
        "#concatenating feature stream from all three model\n",
        "\n",
        "concat = Concatenate()([m1.layers[5].output, m2.layers[10].output, m3.layers[10].output]) \n",
        "# merge = Model([m1.input, m2.input,m3.input], concat)\n",
        "m = Dense(384, activation='relu')(concat)#is 384 taken randomly\n",
        "m = Dropout(0.3)(m)\n",
        "m = Dense(128, activation='relu')(m)\n",
        "m = Dropout(0.1)(m)\n",
        "m = Dense(1, activation='sigmoid')(m)\n",
        "\n",
        "model_final = Model(inputs=[m1.input, m2.input, m3.input], outputs=m)\n",
        "model_final.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y7rWFXtt4O4N"
      },
      "outputs": [],
      "source": [
        "#compiling model\n",
        "model_final.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "KGxkLu3r-Yya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "diFBG5xlPtSK"
      },
      "outputs": [],
      "source": [
        "#model training\n",
        "# NO_OF_EPOCHS=20\n",
        "# BATCH_SIZE=32\n",
        "# checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/final_model/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n",
        "# csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=2, min_lr=0.001)\n",
        "# model_final.fit([x_train,hog_image_train,sift_features_train],y_train,epochs=NO_OF_EPOCHS,verbose=1,batch_size=BATCH_SIZE,validation_data=([x_test,hog_image_test,sift_features_test],y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ],
      "metadata": {
        "id": "Y-KCXK0J-g1h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M5gR-d6xmtYp"
      },
      "outputs": [],
      "source": [
        "#model testing\n",
        "model_final.load_weights(resultPath + \"/final_model/checkpoint-0009.hdf5\")\n",
        "prediction_prob1 = model_final.predict([x_test,hog_image_test,sift_features_test],verbose=1)\n",
        "y_pred=np.round(prediction_prob1)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred,average='binary'))\n",
        "print(recall_score(y_test,y_pred,average='binary'))\n",
        "print(f1_score(y_test,y_pred,average='binary'))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding SVM**"
      ],
      "metadata": {
        "id": "XKCM5Z-t-sdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sVYwXYpHm5_v"
      },
      "outputs": [],
      "source": [
        "# defining submodel\n",
        "m1model = Model(inputs=model_final.input,outputs=model_final.get_layer('dense_10').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IhQyURSwm-kh"
      },
      "outputs": [],
      "source": [
        "#training submodel\n",
        "m1_x_train = m1model.predict([x_train,hog_image_train,sift_features_train],verbose=1)\n",
        "m1_x_test = m1model.predict([x_test,hog_image_test,sift_features_test],verbose=1)\n",
        "print(\"Shape of model1 Train and Test DF : \",m1_x_train.shape,\" : \",m1_x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O-7Fh0BknVDw"
      },
      "outputs": [],
      "source": [
        "#defining accuracy matrix\n",
        "def printMetrics(true,pred):\n",
        "    print(\"Accuracy : \",accuracy_score(true, pred))\n",
        "    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n",
        "    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n",
        "    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n",
        "    print(\"Confusion Matrix : \")\n",
        "    print(confusion_matrix(true, pred))\n",
        "    print(classification_report(true,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o4RJBea5ndcZ"
      },
      "outputs": [],
      "source": [
        "#predicting output after adding SVM\n",
        "RSVM = svm.SVC(kernel='rbf',probability=True)\n",
        "RSVM.fit(m1_x_train, y_train)\n",
        "RSVMprob = RSVM.predict_proba(m1_x_test)\n",
        "y_pred = RSVM.predict(m1_x_test)\n",
        "printMetrics(y_test,y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}